{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5đ\n",
    "\n",
    "# Decision Tree class\n",
    "# You should implement the ID3 algorithm here\n",
    "# You can add other utility methods to make your code easy to read :) \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, feature = None, children = [], vals = [], is_leaf = False):\n",
    "        # YOUR CODE HERE\n",
    "        self.feature = feature # node's name\n",
    "        self.children = children\n",
    "        self.feature_values = vals # values to branch feature\n",
    "        self.is_leaf = is_leaf\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.feature}, children: {self.children}, leaf: {self.is_leaf}\"\n",
    "\n",
    "    def get_entropy(self, y):\n",
    "        probs = y.value_counts() / len(y)\n",
    "        entropy = np.sum(-probs * np.log2(probs))\n",
    "        return entropy\n",
    "    \n",
    "    def get_info_gain(self, X, y, col):\n",
    "        feature_vals = X[col].unique() # distinct values of a feature/col\n",
    "        gain = self.get_entropy(y)\n",
    "        # print(feature_vals)\n",
    "        \n",
    "        for val in feature_vals:\n",
    "            y_val = y.loc[X[col] == val] # y with value /val/ of X[col]\n",
    "            gain -= len(y_val)/len(y) * self.get_entropy(y_val)\n",
    "        return gain\n",
    "        \n",
    "    # bỏ param loop\n",
    "    def fit(self, X_train, y_train, loop=0):\n",
    "        # 4đ \n",
    "        # YOUR CODE HERE\n",
    "        loop += 1\n",
    "        cols = X_train.columns\n",
    "        \n",
    "        # if y_train is purity\n",
    "        if len(y_train.unique()) == 1:\n",
    "            self.is_leaf = True\n",
    "            self.feature = y_train.iloc[0]\n",
    "            return self\n",
    "        \n",
    "        # if loop >= 2:\n",
    "        #     return self\n",
    "        \n",
    "        # if no more data in X_train OR if no cols remaining\n",
    "        if X_train.shape[0] == 0 or len(cols) == 0: # or len(cols) == 0\n",
    "            self.is_leaf = True\n",
    "            self.feature = y_train.value_counts().index[0]\n",
    "            return self\n",
    "        \n",
    "        # find feature with max gain\n",
    "        gains = [self.get_info_gain(X_train, y_train, col) for col in cols]\n",
    "        max_gain_ind = np.argmax(gains)\n",
    "        print(cols)\n",
    "        \n",
    "        # init root\n",
    "        self.feature = cols[max_gain_ind]\n",
    "        \n",
    "        # init root's subtrees\n",
    "        for val in X_train[self.feature].unique():\n",
    "            child = DecisionTree() \n",
    "            \n",
    "            mask = X_train[self.feature] == val # bool array\n",
    "            X_i = X_train[mask].drop(self.feature, axis=1)\n",
    "            y_i = y_train[mask]\n",
    "            \n",
    "            # print(X_train.shape, X_i.shape)\n",
    "            \n",
    "            child.fit(X_i, y_i, loop)\n",
    "            self.feature_values.append(val)\n",
    "            self.children.append(child) # add subtree\n",
    "        \n",
    "        return self \n",
    "\n",
    "    def predict_row(self, row):\n",
    "        if self.is_leaf:\n",
    "            return self.feature\n",
    "        child_i = self.feature_values.index(row[self.feature])\n",
    "        return self.children[child_i].predict_row(row)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        # 0.5đ \n",
    "        # YOUR CODE HERE\n",
    "        if X_test is not None:\n",
    "            y_pred = X_test.apply(lambda x: self.predict_row(x), axis = 1)\n",
    "            return y_pred\n",
    "    \n",
    "    def convert_to_node(self, node_lst, par, par_node):\n",
    "        if par.is_leaf:\n",
    "            leaf = Node(par.feature, parent= par_node)\n",
    "            node_lst.append(leaf) \n",
    "            return\n",
    "        \n",
    "        for child in par.children:\n",
    "            child_node = Node(child.feature, parent= par_node)\n",
    "            node_lst.append(child_node)\n",
    "            self.convert_to_node(node_lst, child, child_node)\n",
    "                \n",
    "    def visualize(self):\n",
    "        # 0.5đ \n",
    "        # YOUR CODE HERE\n",
    "        print(self.feature)\n",
    "        for child, val in zip(self.children, self.feature_values):\n",
    "            print(f\"| {val}\") \n",
    "            \n",
    "        for val in self.feature_values:\n",
    "            print(f'{self.feature} = {val}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X_train, y_train, loop=0):\n",
    "        # 4đ \n",
    "        # YOUR CODE HERE\n",
    "        loop += 1\n",
    "        cols = X_train.columns\n",
    "        \n",
    "        # if y_train is purity\n",
    "        if len(y_train.unique()) == 1:\n",
    "            self.is_leaf = True\n",
    "            self.feature = y_train.iloc[0]\n",
    "            return self\n",
    "        \n",
    "        # if no cols remaining\n",
    "        if X_train.shape[0] == 0 or len(cols) == 0: \n",
    "            self.is_leaf = True\n",
    "            self.feature = y_train.value_counts().index[0]\n",
    "            return self\n",
    "        \n",
    "        # find feature with max gain\n",
    "        gains = [self.get_info_gain(X_train, y_train, col) for col in cols]\n",
    "        best_fea = cols[np.argmax(gains)]\n",
    "        \n",
    "        # init root\n",
    "        self.feature = best_fea\n",
    "        \n",
    "        # build root's subtrees\n",
    "        children_node = []\n",
    "        for val in X_train[best_fea].unique():\n",
    "            # print(X_train[best_attrib].unique(), val)\n",
    "            child = DecisionTree() \n",
    "            self.feature_values.append(val)\n",
    "            \n",
    "            mask = X_train[best_fea] == val # bool array\n",
    "            X_i = X_train[mask].copy().drop(columns = best_fea)\n",
    "            y_i = y_train[mask].copy()\n",
    "            \n",
    "            child.fit(X_i, y_i, loop)\n",
    "            self.children.append(child) # add subtree\n",
    "            #-------------------------------------------\n",
    "        #     child_node = Node(child.feature)\n",
    "        #     children_node.append(child_node)\n",
    "        # par_node = Node(self.feature, children= children_node)\n",
    "        # self.node_lst.append(par_node)\n",
    "        \n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # for each branch\n",
    "        for i in range(len(self.feature_values)):\n",
    "            val = self.feature_values[i]\n",
    "            child = self.children[i]\n",
    "            \n",
    "            par_node = Node(f'{self.feature} = {val}', parent= par)\n",
    "            child.visualize(par_node)\n",
    "            self.node = par_node\n",
    "        \n",
    "        if par is None:\n",
    "            for pre, fill, node in RenderTree(self.node):\n",
    "                print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if par is None: # tree's root\n",
    "    par_node = Node(self.feature)\n",
    "else: # other nodes\n",
    "    par_node = Node(self.feature, parent= par)\n",
    "\n",
    "for child in self.children:\n",
    "    child.visualize(par_node)\n",
    "self.node = par_node\n",
    "\n",
    "if par is None:\n",
    "    for pre, fill, node in RenderTree(self.node):\n",
    "        print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5đ\n",
    "\n",
    "# Decision Tree class\n",
    "# You should implement the ID3 algorithm here\n",
    "# You can add other utility methods to make your code easy to read :) \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, feature = None, children = [], vals = [], is_leaf = False):\n",
    "        # YOUR CODE HERE\n",
    "        self.feature = feature # node's name\n",
    "        self.children = children\n",
    "        self.feature_values = vals # values to branch feature\n",
    "        self.is_leaf = is_leaf\n",
    "        self.node = None\n",
    "        self.node_lst = []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.feature}, [{self.children}]\"\n",
    "\n",
    "    def get_entropy(self, y):\n",
    "        probs = y.value_counts() / len(y)\n",
    "        entropy = np.sum(-probs * np.log2(probs))\n",
    "        return entropy\n",
    "    \n",
    "    def get_info_gain(self, X, y, col):\n",
    "        feature_vals = X[col].unique() # distinct values of a feature/col\n",
    "        gain = self.get_entropy(y)\n",
    "        # print(feature_vals)\n",
    "        \n",
    "        for val in feature_vals:\n",
    "            y_val = y.loc[X[col] == val] # y with value /val/ of X[col]\n",
    "            gain -= len(y_val)/len(y) * self.get_entropy(y_val)\n",
    "        return gain\n",
    "        \n",
    "    # bỏ param loop\n",
    "    def fit(self, X_train, y_train, par= None):\n",
    "        # 4đ \n",
    "        # YOUR CODE HERE\n",
    "        cols = X_train.columns\n",
    "        \n",
    "        # if y_train is purity\n",
    "        if len(y_train.unique()) == 1:\n",
    "            self.is_leaf = True\n",
    "            self.feature = y_train.iloc[0]\n",
    "            leaf_node = Node(f'Decision = {self.feature}', parent= par)\n",
    "            return self\n",
    "        \n",
    "        # no cols remaining\n",
    "        if len(cols) == 0: \n",
    "            self.is_leaf = True\n",
    "            self.feature = y_train.value_counts().index[0]\n",
    "            leaf_node = Node(f'Decision = {self.feature}', parent= par)\n",
    "            return self\n",
    "        \n",
    "        # find feature with max gain\n",
    "        gains = [self.get_info_gain(X_train, y_train, col) for col in cols]\n",
    "        best_fea = cols[np.argmax(gains)]\n",
    "        \n",
    "        # init root\n",
    "        self.feature = best_fea\n",
    "        self.feature_values = X_train[best_fea].unique().tolist()\n",
    "        self.node = Node(f'{best_fea}', parent = par)\n",
    "        # print(gains, np.argmax(gains))\n",
    "        \n",
    "        # init root's subtrees\n",
    "        children = []\n",
    "        for val in self.feature_values:\n",
    "            parent_node = Node(f'{best_fea} = {val}', parent= self.node)\n",
    "            children.append(DecisionTree())\n",
    "            \n",
    "            mask = X_train[best_fea] == val # bool array\n",
    "            X_i = X_train[mask].drop(best_fea, axis=1)\n",
    "            y_i = y_train[mask]\n",
    "            \n",
    "            children[-1].fit(X_i, y_i, parent_node)\n",
    "            \n",
    "        self.children = children\n",
    "        return self \n",
    "\n",
    "    def predict_row(self, row):\n",
    "        if self.is_leaf:\n",
    "            return self.feature\n",
    "        # print(row, self.feature_values)\n",
    "        child_i = self.feature_values.index(row[self.feature])\n",
    "        return self.children[child_i].predict_row(row)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        # 0.5đ \n",
    "        # YOUR CODE HERE\n",
    "        if X_test is not None:\n",
    "            y_pred = X_test.apply(lambda x: self.predict_row(x), axis = 1)\n",
    "            return y_pred\n",
    "    \n",
    "    def visualize(self, par=None):\n",
    "        # 0.5đ \n",
    "        # YOUR CODE HERE\n",
    "        # branches = self.feature_values\n",
    "        # children = self.children\n",
    "        \n",
    "        # # for each branch\n",
    "        # for i in range(len(branches)):\n",
    "        #     branch_name = branches[i]\n",
    "        #     child = children[i]\n",
    "            \n",
    "        #     par_node = Node(f'{self.feature} = {branch_name}', parent= par)\n",
    "        #     child.visualize(par_node)\n",
    "        #     self.node = par_node\n",
    "        \n",
    "        if par is None:\n",
    "            for pre, fill, node in RenderTree(self.node):\n",
    "                print(\"%s%s\" % (pre, node.name))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
